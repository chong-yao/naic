{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeFpCr0HIkzt",
        "outputId": "5fe4d6b0-220f-4007-af3d-4d251ae7fe6e"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWRzu2GaK1p3"
      },
      "source": [
        "# Download files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ye75SyJc_m",
        "outputId": "ce9c1436-7864-4bad-d370-10217235ba6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 1vA70lsUOr-TYG7337eQ7Z-X4J7WbLvVD [TMP] cnn kuih-scratch.pt\n",
            "Processing file 1_10GTTSqYCDbFgEdzRyU3YUXgaGc8aqN [TMP] labels.txt\n",
            "Processing file 11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe [TMP] vit_kuih_balanced_epoch42_loss0.001_0.9114acc.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vA70lsUOr-TYG7337eQ7Z-X4J7WbLvVD\n",
            "From (redirected): https://drive.google.com/uc?id=1vA70lsUOr-TYG7337eQ7Z-X4J7WbLvVD&confirm=t&uuid=041217d8-4811-4b6d-af08-4927c2546b56\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\model\\[TMP] cnn kuih-scratch.pt\n",
            "100%|██████████| 125M/125M [00:04<00:00, 25.1MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_10GTTSqYCDbFgEdzRyU3YUXgaGc8aqN\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\model\\[TMP] labels.txt\n",
            "100%|██████████| 124/124 [00:00<?, ?B/s] \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe\n",
            "From (redirected): https://drive.google.com/uc?id=11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe&confirm=t&uuid=0f361c9f-c32a-47d3-a8be-ac879e735507\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\model\\[TMP] vit_kuih_balanced_epoch42_loss0.001_0.9114acc.pth\n",
            "100%|██████████| 343M/343M [00:18<00:00, 18.9MB/s] \n",
            "Download completed\n",
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving folder 1qO-cQtRdp-hLu6LMQ68OEv0zA791puJO test_images\n",
            "Processing file 1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH Kek Lapis.jpg\n",
            "Processing file 1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4 Kuih Kaswi Pandan.jpg\n",
            "Processing file 11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6 Kuih Ketayap.jpg\n",
            "Processing file 1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM Kuih Lapis.jpg\n",
            "Processing file 17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB- Kuih Seri Muka.png\n",
            "Processing file 1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR Kuih Talam.jpg\n",
            "Processing file 1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7 Kuih Ubi Kayu.jpg\n",
            "Processing file 1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF Onde-Onde.jpg\n",
            "Processing file 12ufiwhl6whVp33F05RLiDRieRSN13XlP test_labels.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kek Lapis.jpg\n",
            "100%|██████████| 1.27M/1.27M [00:00<00:00, 1.57MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Kaswi Pandan.jpg\n",
            "100%|██████████| 418k/418k [00:00<00:00, 9.18MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Ketayap.jpg\n",
            "100%|██████████| 373k/373k [00:00<00:00, 6.78MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Lapis.jpg\n",
            "100%|██████████| 56.6k/56.6k [00:00<00:00, 4.19MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB-\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Seri Muka.png\n",
            "100%|██████████| 1.04M/1.04M [00:00<00:00, 7.55MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Talam.jpg\n",
            "100%|██████████| 16.8k/16.8k [00:00<00:00, 8.40MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Kuih Ubi Kayu.jpg\n",
            "100%|██████████| 155k/155k [00:00<00:00, 4.88MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_images\\Onde-Onde.jpg\n",
            "100%|██████████| 95.9k/95.9k [00:00<00:00, 6.12MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12ufiwhl6whVp33F05RLiDRieRSN13XlP\n",
            "To: c:\\Users\\ochon\\OneDrive - student.newinti.edu.my\\NAIC_submission\\naic\\test_folder\\test_labels.txt\n",
            "100%|██████████| 283/283 [00:00<00:00, 36.7kB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['test_folder\\\\test_images\\\\Kek Lapis.jpg',\n",
              " 'test_folder\\\\test_images\\\\Kuih Kaswi Pandan.jpg',\n",
              " 'test_folder\\\\test_images\\\\Kuih Ketayap.jpg',\n",
              " 'test_folder\\\\test_images\\\\Kuih Lapis.jpg',\n",
              " 'test_folder\\\\test_images\\\\Kuih Seri Muka.png',\n",
              " 'test_folder\\\\test_images\\\\Kuih Talam.jpg',\n",
              " 'test_folder\\\\test_images\\\\Kuih Ubi Kayu.jpg',\n",
              " 'test_folder\\\\test_images\\\\Onde-Onde.jpg',\n",
              " 'test_folder\\\\test_labels.txt']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "#download model\n",
        "gdown.download_folder(id='1QVWjX8Aa2VvIbXjDY4DyqcV_Uqw6myX7', output=\"model\", quiet=False, use_cookies=False)\n",
        "\n",
        "#download test ds\n",
        "gdown.download_folder(id='1LZIhiV9l82W4fNpfaBHyGvh8XBX6SoU2', output=\"test_folder\", quiet=False, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezrdTSBSK4tB"
      },
      "source": [
        "# Load CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9KGUYRtInXF",
        "outputId": "adbdddff-8bef-4046-c8f9-36b768911744"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "cnn = YOLO(\"model/[TMP] cnn kuih-scratch.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Eva(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (rope): RotaryEmbeddingCat()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x EvaBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): EvaAttention(\n",
              "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): SwiGLU(\n",
              "        (fc1_g): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (fc1_x): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (act): SiLU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
              "        (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): Identity()\n",
              "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import timm\n",
        "import torch\n",
        "\n",
        "vit = timm.create_model(\n",
        "    'eva02_base_patch14_224.mim_in22k', pretrained=False, num_classes=8)\n",
        "\n",
        "vit.load_state_dict(torch.load(\"model/[TMP] vit_kuih_balanced_epoch42_loss0.001_0.9114acc.pth\"))\n",
        "\n",
        "vit.eval().cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "vit_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ARD7OneK7m-"
      },
      "source": [
        "# Load labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4rxPynozK9bt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Kek Lapis', 1: 'Kuih Kaswi Pandan', 2: 'Kuih Ketayap', 3: 'Kuih Lapis', 4: 'Kuih Seri Muka', 5: 'Kuih Talam', 6: 'Kuih Ubi Kayu', 7: 'Onde-Onde'}\n"
          ]
        }
      ],
      "source": [
        "with open('model/[TMP] labels.txt') as f:\n",
        "    labels = {i: line.strip().split(' ', 1)[1] for i, line in enumerate(f)}\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCF4pb9RLYmy"
      },
      "source": [
        "# Load test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "plLuztQkLZ-C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "test_images = [os.path.join(r, f) for r, d, fs in os.walk('test_folder/test_images') for f in fs if f.lower().endswith(('.png', '.jpg', '.jpeg'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af3qD8cTLoOH"
      },
      "source": [
        "# CNN predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "D1cERQ3iLlMm"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "num_classes = 8\n",
        "cnn_predictions = []\n",
        "\n",
        "for path in test_images:\n",
        "    cnn_results = cnn(path, verbose=False)\n",
        "    cnn_pred_classes = cnn_results[0].boxes.cls.tolist()  # List of detected class IDs\n",
        "\n",
        "    if len(cnn_pred_classes) > 0:\n",
        "        cnn_counts = Counter(cnn_pred_classes)\n",
        "        cnn_probs = [cnn_counts.get(i, 0) for i in range(num_classes)]\n",
        "        cnn_probs = [p / sum(cnn_probs) for p in cnn_probs]  # normalize to sum to 1\n",
        "        cnn_predicted_class_idx = int(max(cnn_counts, key=cnn_counts.get))\n",
        "    else:\n",
        "        cnn_probs = [0.0] * num_classes\n",
        "        cnn_predicted_class_idx = -1\n",
        "\n",
        "    cnn_predictions.append({\n",
        "        'image': os.path.basename(path),\n",
        "        'predicted_class_index': cnn_predicted_class_idx,\n",
        "        'predicted_label': labels.get(cnn_predicted_class_idx, 'Unknown'),\n",
        "        'class_probabilities': cnn_probs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ViT predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'image': 'Kek Lapis.jpg', 'predicted_class_index': 0, 'predicted_label': 'Kek Lapis', 'class_probabilities': [0.9998119473457336, 2.198139191023074e-05, 2.3216711269924417e-05, 3.766033478314057e-05, 2.7468433472677134e-05, 2.6428735509398393e-05, 2.85113765130518e-05, 2.2864156562718563e-05]}, {'image': 'Kuih Kaswi Pandan.jpg', 'predicted_class_index': 1, 'predicted_label': 'Kuih Kaswi Pandan', 'class_probabilities': [2.219474481535144e-05, 0.9998972415924072, 1.8593278582557105e-05, 2.008783667406533e-05, 1.4045052012079395e-05, 1.1336949683027342e-05, 1.0026218660641462e-05, 6.448815383919282e-06]}, {'image': 'Kuih Ketayap.jpg', 'predicted_class_index': 2, 'predicted_label': 'Kuih Ketayap', 'class_probabilities': [1.139003779826453e-05, 1.3869734175386839e-05, 0.9999198913574219, 9.086344107345212e-06, 1.0420495527796447e-05, 1.1227072718611453e-05, 9.811956260818988e-06, 1.4303744137578178e-05]}, {'image': 'Kuih Lapis.jpg', 'predicted_class_index': 3, 'predicted_label': 'Kuih Lapis', 'class_probabilities': [5.841667007189244e-05, 3.009169813594781e-05, 2.3217429770738818e-05, 0.99977046251297, 2.796222543111071e-05, 3.149257827317342e-05, 2.737098839133978e-05, 3.096113141509704e-05]}, {'image': 'Kuih Seri Muka.png', 'predicted_class_index': 4, 'predicted_label': 'Kuih Seri Muka', 'class_probabilities': [1.4321046364784706e-05, 1.616243207536172e-05, 1.2784402315446641e-05, 1.39699013743666e-05, 0.9999080896377563, 1.4388660929398611e-05, 1.1212987374165095e-05, 9.139484063780401e-06]}, {'image': 'Kuih Talam.jpg', 'predicted_class_index': 5, 'predicted_label': 'Kuih Talam', 'class_probabilities': [1.3167639735911507e-05, 1.2136812074459158e-05, 1.1066312254115473e-05, 1.3946809303888585e-05, 1.3211691111791879e-05, 0.9999121427536011, 1.1822029591712635e-05, 1.2464706742321141e-05]}, {'image': 'Kuih Ubi Kayu.jpg', 'predicted_class_index': 6, 'predicted_label': 'Kuih Ubi Kayu', 'class_probabilities': [1.2355124454188626e-05, 1.1472133337520063e-05, 1.0525453035370447e-05, 1.1296017873974051e-05, 1.2430550668796059e-05, 1.3341505109565333e-05, 0.9999176263809204, 1.0970363291562535e-05]}, {'image': 'Onde-Onde.jpg', 'predicted_class_index': 7, 'predicted_label': 'Onde-Onde', 'class_probabilities': [1.3877181118004955e-05, 1.31991846501478e-05, 1.2854003216489218e-05, 1.2150698239565827e-05, 1.2754970157402568e-05, 1.271945166081423e-05, 1.2249536666786298e-05, 0.9999102354049683]}]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "vit_predictions = []\n",
        "\n",
        "for path in test_images:\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    input_tensor = vit_transform(image).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vit_logits = vit(input_tensor)\n",
        "\n",
        "    vit_probs_tensor = F.softmax(vit_logits, dim=1).squeeze(0)\n",
        "    vit_probs = vit_probs_tensor.tolist()\n",
        "\n",
        "    vit_predicted_class_idx = int(torch.argmax(vit_probs_tensor).item())\n",
        "\n",
        "    vit_predictions.append({\n",
        "        'image': os.path.basename(path),\n",
        "        'predicted_class_index': vit_predicted_class_idx,\n",
        "        'predicted_label': labels.get(vit_predicted_class_idx, 'Unknown'),\n",
        "        'class_probabilities': vit_probs\n",
        "    })\n",
        "\n",
        "print(vit_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combine model outputs and decide on one class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_predictions = []\n",
        "\n",
        "for cnn, vit in zip(cnn_predictions, vit_predictions):\n",
        "    assert cnn['image'] == vit['image'], \"Mismatch in image order\"\n",
        "\n",
        "    cnn_idx = cnn['predicted_class_index']\n",
        "    vit_idx = vit['predicted_class_index']\n",
        "    cnn_probs = cnn['class_probabilities']\n",
        "    vit_probs = vit['class_probabilities']\n",
        "\n",
        "    #average probabilities (soft voting)\n",
        "    final_probs = [(c + v) / 2 for c, v in zip(cnn_probs, vit_probs)]\n",
        "\n",
        "    # Decide class index from final_probs\n",
        "    if cnn_idx == vit_idx and cnn_idx != -1: #models cohere\n",
        "        final_idx = cnn_idx\n",
        "\n",
        "    elif cnn_idx == -1 and vit_idx != -1: #CNN no output, ViT has output, follow ViT\n",
        "        final_idx = vit_idx\n",
        "\n",
        "    elif vit_idx == -1 and cnn_idx != -1: #ViT no output, CNN has output, follow CNN\n",
        "        final_idx = cnn_idx\n",
        "\n",
        "    elif cnn_idx != -1 and vit_idx != -1: #models disagree, compare confidences from both models using soft voting\n",
        "        final_idx = int(torch.tensor(final_probs).argmax().item())\n",
        "    else:\n",
        "        final_idx = -1  #both models no output\n",
        "\n",
        "    final_predictions.append({\n",
        "        'image': cnn['image'],\n",
        "        'predicted_class_index': final_idx,\n",
        "        'predicted_label': labels.get(final_idx, 'Unknown'),\n",
        "        'class_probabilities': final_probs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETnBcJfcNQOW"
      },
      "source": [
        "# Save results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpAgJ5JcNRVj",
        "outputId": "dce2491b-fe05-4113-8f42-e3465bf07089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   image  predicted_class_index    predicted_label  \\\n",
            "0          Kek Lapis.jpg                      0          Kek Lapis   \n",
            "1  Kuih Kaswi Pandan.jpg                      1  Kuih Kaswi Pandan   \n",
            "2       Kuih Ketayap.jpg                      2       Kuih Ketayap   \n",
            "3         Kuih Lapis.jpg                      3         Kuih Lapis   \n",
            "4     Kuih Seri Muka.png                      4     Kuih Seri Muka   \n",
            "5         Kuih Talam.jpg                      5         Kuih Talam   \n",
            "6      Kuih Ubi Kayu.jpg                      6      Kuih Ubi Kayu   \n",
            "7          Onde-Onde.jpg                      7          Onde-Onde   \n",
            "\n",
            "                                 class_probabilities  \n",
            "0  [0.9999059736728668, 1.099069595511537e-05, 1....  \n",
            "1  [1.109737240767572e-05, 0.9999486207962036, 9....  \n",
            "2  [5.695018899132265e-06, 6.934867087693419e-06,...  \n",
            "3  [2.920833503594622e-05, 1.5045849067973904e-05...  \n",
            "4  [7.160523182392353e-06, 8.08121603768086e-06, ...  \n",
            "5  [6.583819867955754e-06, 6.068406037229579e-06,...  \n",
            "6  [6.177562227094313e-06, 5.7360666687600315e-06...  \n",
            "7  [6.938590559002478e-06, 6.5995923250739e-06, 0...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "final_results_df = pd.DataFrame(final_predictions)\n",
        "print(final_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxzdFncN8hB"
      },
      "source": [
        "# Map the true labels of the images in the testing folder to model's class index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tAm29rH2ODc3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('test_folder/test_labels.txt')\n",
        "\n",
        "filename_to_class = dict(zip(df_test['Filename'].str.strip(), df_test['Class'].str.strip()))\n",
        "\n",
        "label_to_class_index = {v.strip(): k for k, v in labels.items()}\n",
        "\n",
        "true_class_index = [label_to_class_index[filename_to_class[os.path.basename(path).strip()]] for path in test_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V_uh8KJROLrO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "final_results_df['true_class_index'] = true_class_index  ## changes here in v2 - refer to true_class_index\n",
        "y_true = final_results_df['true_class_index'].astype(int).values\n",
        "y_pred = final_results_df['predicted_class_index'].astype(int).values\n",
        "y_probs = np.array(final_results_df['class_probabilities'].tolist())\n",
        "\n",
        "n_classes=8\n",
        "\n",
        "# Pad probability vectors to length 8\n",
        "def pad_probs(probs, target_len=n_classes):\n",
        "    padded = np.zeros(target_len)\n",
        "    padded[:len(probs)] = probs  # assumes probs are in order (class 0, 1, 2, ...)\n",
        "    return padded\n",
        "\n",
        "# Apply padding\n",
        "y_probs_padded = np.array([pad_probs(p, n_classes) for p in final_results_df['class_probabilities']])\n",
        "\n",
        "# Update your DataFrame or use directly in metrics\n",
        "y_probs = y_probs_padded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g44fTDfKQ0QY",
        "outputId": "60821af4-83b6-4fe0-bae5-aaa6f340f994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Accuracy: 1.0000\n",
            "\n",
            "📊 Per-class metrics:\n",
            "Class 0: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 1: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 2: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 3: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 4: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 5: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 6: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 7: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "\n",
            "📦 Macro Precision: 1.0000, Macro Recall: 1.0000, Macro F1: 1.0000\n",
            "\n",
            "🎯 ROC AUC per class:\n",
            "Class 0: AUC = 1.0000\n",
            "Class 1: AUC = 1.0000\n",
            "Class 2: AUC = 1.0000\n",
            "Class 3: AUC = 1.0000\n",
            "Class 4: AUC = 1.0000\n",
            "Class 5: AUC = 1.0000\n",
            "Class 6: AUC = 1.0000\n",
            "Class 7: AUC = 1.0000\n",
            "\n",
            "🌐 Macro ROC AUC: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Number of classes\n",
        "class_names = list(range(n_classes))\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\n✅ Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Precision, Recall, F1 per class & macro\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_names, average=None)\n",
        "macro_prec, macro_rec, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "\n",
        "print(\"\\n📊 Per-class metrics:\")\n",
        "for i, cls in enumerate(class_names):\n",
        "    print(f\"Class {cls}: Precision={prec[i]:.4f}, Recall={rec[i]:.4f}, F1={f1[i]:.4f}\")\n",
        "\n",
        "print(f\"\\n📦 Macro Precision: {macro_prec:.4f}, Macro Recall: {macro_rec:.4f}, Macro F1: {macro_f1:.4f}\")\n",
        "\n",
        "# ROC AUC (requires binarized labels)\n",
        "y_true_bin = label_binarize(y_true, classes=class_names)\n",
        "\n",
        "# ROC AUC per class and macro\n",
        "try:\n",
        "    auc_per_class = roc_auc_score(y_true_bin, y_probs, average=None, multi_class='ovr')\n",
        "    auc_macro = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n",
        "\n",
        "    print(\"\\n🎯 ROC AUC per class:\")\n",
        "    for i, cls in enumerate(class_names):\n",
        "        print(f\"Class {cls}: AUC = {auc_per_class[i]:.4f}\")\n",
        "\n",
        "    print(f\"\\n🌐 Macro ROC AUC: {auc_macro:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ ROC AUC could not be computed: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
