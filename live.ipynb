{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NeFpCr0HIkzt"
      },
      "outputs": [],
      "source": [
        "# Ensure you have a CUDA-compatible version of PyTorch installed.\n",
        "!pip install -q ultralytics timm opencv-python Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezrdTSBSK4tB"
      },
      "source": [
        "# Load CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v9KGUYRtInXF"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# The YOLO model from ultralytics will automatically use the GPU if available.\n",
        "# We will explicitly specify the device during the inference call for clarity and certainty.\n",
        "cnn = YOLO(\"models/cnn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy69EVJRlijd"
      },
      "source": [
        "# Load ViT model and move to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uccgPddWlije"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Eva(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (rope): RotaryEmbeddingCat()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x EvaBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): EvaAttention(\n",
              "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): SwiGLU(\n",
              "        (fc1_g): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (fc1_x): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (act): SiLU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
              "        (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): Identity()\n",
              "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import timm\n",
        "import torch\n",
        "\n",
        "# Define the device to use (CUDA or CPU). This is the standard practice.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create the model and move it to the defined device immediately.\n",
        "vit = timm.create_model('eva02_base_patch14_224.mim_in22k', pretrained=False, num_classes=8).to(device)\n",
        "\n",
        "# Load the model weights, mapping them to the same device to prevent errors.\n",
        "vit.load_state_dict(torch.load(\"models/vit.pth\", map_location=device))\n",
        "\n",
        "# Set to evaluation mode. The model is already on the correct device.\n",
        "vit.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6aed2csNlije"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# These transforms run on the CPU to prepare the image data before it's sent to the GPU.\n",
        "vit_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ARD7OneK7m-"
      },
      "source": [
        "# Load labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4rxPynozK9bt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Kek Lapis', 1: 'Kuih Kaswi Pandan', 2: 'Kuih Ketayap', 3: 'Kuih Lapis', 4: 'Kuih Seri Muka', 5: 'Kuih Talam', 6: 'Kuih Ubi Kayu', 7: 'Onde-Onde'}\n"
          ]
        }
      ],
      "source": [
        "with open('models/labels.txt') as f:\n",
        "    labels = {i: line.strip().split(' ', 1)[1] for i, line in enumerate(f)}\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Camera initialized.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 8\n",
        "\n",
        "# This CameraThread class correctly uses CPU-based libraries for capturing frames.\n",
        "class CameraThread:\n",
        "    def __init__(self, src=0):\n",
        "        self.cap = cv2.VideoCapture(src)\n",
        "        if not self.cap.isOpened():\n",
        "            raise IOError(f\"Cannot open webcam at index {src}. \"\n",
        "                          \"Try a different index or check if the camera is used by another application.\")\n",
        "\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "        self.running = True\n",
        "        self.frame = None\n",
        "        self.thread = Thread(target=self.update, daemon=True)\n",
        "        self.thread.start()\n",
        "\n",
        "    def update(self):\n",
        "        while self.running:\n",
        "            ret, frame = self.cap.read()\n",
        "            if ret:\n",
        "                self.frame = frame\n",
        "            else:\n",
        "                self.running = False\n",
        "\n",
        "    def read(self):\n",
        "        return self.frame\n",
        "\n",
        "    def release(self):\n",
        "        self.running = False\n",
        "        if self.thread.is_alive():\n",
        "            self.thread.join()\n",
        "        self.cap.release()\n",
        "        print(\"Camera released.\")\n",
        "\n",
        "def center_crop(image, crop_width, crop_height):\n",
        "    \"\"\"\n",
        "    Performs a center crop on an image.\n",
        "\n",
        "    Args:\n",
        "        image: The input image (as a NumPy array).\n",
        "        crop_width: The desired width of the cropped image.\n",
        "        crop_height: The desired height of the cropped image.\n",
        "\n",
        "    Returns:\n",
        "        The center-cropped image.\n",
        "    \"\"\"\n",
        "    original_height, original_width, _ = image.shape\n",
        "\n",
        "    # Calculate the center of the image\n",
        "    center_x = original_width // 2\n",
        "    center_y = original_height // 2\n",
        "\n",
        "    # Calculate the starting and ending coordinates for the crop\n",
        "    start_x = center_x - (crop_width // 2)\n",
        "    end_x = start_x + crop_width\n",
        "    start_y = center_y - (crop_height // 2)\n",
        "    end_y = start_y + crop_height\n",
        "\n",
        "    # Perform the crop using NumPy slicing\n",
        "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "# --- Main Inference Loop ---\n",
        "try:\n",
        "    cam = CameraThread(src=1)\n",
        "    print(\"Camera initialized.\")\n",
        "    time.sleep(2.0)\n",
        "    print(\"Starting inference loop...\")\n",
        "\n",
        "    while True:\n",
        "        frame = cam.read()\n",
        "        if frame is None:\n",
        "            time.sleep(0.1)\n",
        "            continue\n",
        "\n",
        "        frame = center_crop(frame, 448, 448)\n",
        "\n",
        "        # --- 1. CNN Prediction (on GPU) ---\n",
        "        cnn_results = cnn(frame, device=device, verbose=False)\n",
        "        cnn_pred_classes = cnn_results[0].boxes.cls.tolist()\n",
        "\n",
        "        if cnn_pred_classes:\n",
        "            cnn_counts = Counter(cnn_pred_classes)\n",
        "            cnn_probs = [cnn_counts.get(float(i), 0) for i in range(num_classes)]\n",
        "            if sum(cnn_probs) > 0:\n",
        "                cnn_probs = [p / sum(cnn_probs) for p in cnn_probs]\n",
        "            cnn_predicted_class_idx = int(max(cnn_counts, key=cnn_counts.get))\n",
        "        else:\n",
        "            cnn_probs = [0.0] * num_classes\n",
        "            cnn_predicted_class_idx = -1\n",
        "\n",
        "        # --- 2. ViT Prediction (on GPU) ---\n",
        "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(image_rgb)\n",
        "        input_tensor = vit_transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vit_logits = vit(input_tensor)\n",
        "\n",
        "        vit_probs_tensor = F.softmax(vit_logits, dim=1).squeeze(0).cpu()\n",
        "        vit_probs = vit_probs_tensor.tolist()\n",
        "        vit_predicted_class_idx = int(torch.argmax(vit_probs_tensor).item())\n",
        "\n",
        "        # --- 3. Combine Predictions (Ensemble on CPU) ---\n",
        "        final_probs = [(c + v) / 2 for c, v in zip(cnn_probs, vit_probs)]\n",
        "\n",
        "        if cnn_predicted_class_idx == vit_predicted_class_idx and cnn_predicted_class_idx != -1:\n",
        "            final_idx = cnn_predicted_class_idx\n",
        "        else:\n",
        "            final_idx = np.argmax(final_probs)\n",
        "\n",
        "        final_label = labels.get(final_idx, 'Detecting...')\n",
        "        cnn_label = labels.get(cnn_predicted_class_idx, 'Detecting...')\n",
        "        vit_label = labels.get(vit_predicted_class_idx, 'Detecting...')\n",
        "\n",
        "        # Get the probability scores for the predicted classes\n",
        "        final_prob = final_probs[final_idx] if final_idx != -1 else 0\n",
        "        cnn_prob = cnn_probs[cnn_predicted_class_idx] if cnn_predicted_class_idx != -1 else 0\n",
        "        vit_prob = vit_probs[vit_predicted_class_idx] if vit_predicted_class_idx != -1 else 0\n",
        "\n",
        "        # --- 4. Display the result on the frame (on CPU) ---\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.75\n",
        "        color = (255, 255, 255)\n",
        "        thickness = 2\n",
        "        line_type = cv2.LINE_AA\n",
        "\n",
        "        x = 10\n",
        "        y_start = 40\n",
        "        line_height = int(font_scale * 30)\n",
        "\n",
        "        # Display predictions with their probabilities\n",
        "        cv2.putText(frame, f'Ensemble: {final_label} ({final_prob:.2f})', (x, y_start), font, font_scale, color, thickness, line_type)\n",
        "        cv2.putText(frame, f'CNN: {cnn_label} ({cnn_prob:.2f})', (x, y_start + line_height), font, font_scale-0.2, color, thickness, line_type)\n",
        "        cv2.putText(frame, f'ViT: {vit_label} ({vit_prob:.2f})', (x, y_start + 2 * line_height), font, font_scale-0.2, color, thickness, line_type)\n",
        "\n",
        "        # --- Display in Notebook (on CPU) ---\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(frame_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "except (KeyboardInterrupt, IOError) as e:\n",
        "    print(f\"Stopping due to: {e}\")\n",
        "finally:\n",
        "    if 'cam' in locals() and cam.cap.isOpened():\n",
        "        cam.release()\n",
        "    plt.close('all')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "naic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
