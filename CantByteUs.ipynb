{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI2Gl796nrBW"
      },
      "source": [
        "# **P.S. This entire notebook was coded to run on a CPU for compatibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeFpCr0HIkzt",
        "outputId": "edfeb020-c413-410b-fde8-3a791621ba74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWRzu2GaK1p3"
      },
      "source": [
        "# Download files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84ye75SyJc_m",
        "outputId": "161fd246-35e1-47a1-b61b-897ede552f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1wPp6Yx6uqFJH1mCx6I5wHCY2UsRFHecj cnn.pt\n",
            "Processing file 1_10GTTSqYCDbFgEdzRyU3YUXgaGc8aqN labels.txt\n",
            "Processing file 11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe vit.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1wPp6Yx6uqFJH1mCx6I5wHCY2UsRFHecj\n",
            "From (redirected): https://drive.google.com/uc?id=1wPp6Yx6uqFJH1mCx6I5wHCY2UsRFHecj&confirm=t&uuid=ff8900c4-dcb5-4582-88fe-0f90f4a2a6ca\n",
            "To: /content/model/cnn.pt\n",
            "100%|██████████| 125M/125M [00:04<00:00, 28.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_10GTTSqYCDbFgEdzRyU3YUXgaGc8aqN\n",
            "To: /content/model/labels.txt\n",
            "100%|██████████| 124/124 [00:00<00:00, 405kB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe\n",
            "From (redirected): https://drive.google.com/uc?id=11sJJF6_W7UbGbskoFSBZ0dMTzkHNCLBe&confirm=t&uuid=156fa7d5-541f-40fe-8b9c-ec531d1cee74\n",
            "To: /content/model/vit.pth\n",
            "100%|██████████| 343M/343M [00:04<00:00, 73.8MB/s]\n",
            "Download completed\n",
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 1qO-cQtRdp-hLu6LMQ68OEv0zA791puJO test_images\n",
            "Processing file 1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH Kek Lapis.jpg\n",
            "Processing file 1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4 Kuih Kaswi Pandan.jpg\n",
            "Processing file 11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6 Kuih Ketayap.jpg\n",
            "Processing file 1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM Kuih Lapis.jpg\n",
            "Processing file 17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB- Kuih Seri Muka.png\n",
            "Processing file 1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR Kuih Talam.jpg\n",
            "Processing file 1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7 Kuih Ubi Kayu.jpg\n",
            "Processing file 1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF Onde-Onde.jpg\n",
            "Processing file 12ufiwhl6whVp33F05RLiDRieRSN13XlP test_labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH\n",
            "To: /content/test_folder/test_images/Kek Lapis.jpg\n",
            "100%|██████████| 1.27M/1.27M [00:00<00:00, 131MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4\n",
            "To: /content/test_folder/test_images/Kuih Kaswi Pandan.jpg\n",
            "100%|██████████| 418k/418k [00:00<00:00, 66.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6\n",
            "To: /content/test_folder/test_images/Kuih Ketayap.jpg\n",
            "100%|██████████| 373k/373k [00:00<00:00, 91.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM\n",
            "To: /content/test_folder/test_images/Kuih Lapis.jpg\n",
            "100%|██████████| 56.6k/56.6k [00:00<00:00, 51.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB-\n",
            "To: /content/test_folder/test_images/Kuih Seri Muka.png\n",
            "100%|██████████| 1.04M/1.04M [00:00<00:00, 62.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR\n",
            "To: /content/test_folder/test_images/Kuih Talam.jpg\n",
            "100%|██████████| 16.8k/16.8k [00:00<00:00, 21.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7\n",
            "To: /content/test_folder/test_images/Kuih Ubi Kayu.jpg\n",
            "100%|██████████| 155k/155k [00:00<00:00, 67.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF\n",
            "To: /content/test_folder/test_images/Onde-Onde.jpg\n",
            "100%|██████████| 95.9k/95.9k [00:00<00:00, 20.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12ufiwhl6whVp33F05RLiDRieRSN13XlP\n",
            "To: /content/test_folder/test_labels.txt\n",
            "100%|██████████| 283/283 [00:00<00:00, 1.01MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_folder/test_images/Kek Lapis.jpg',\n",
              " 'test_folder/test_images/Kuih Kaswi Pandan.jpg',\n",
              " 'test_folder/test_images/Kuih Ketayap.jpg',\n",
              " 'test_folder/test_images/Kuih Lapis.jpg',\n",
              " 'test_folder/test_images/Kuih Seri Muka.png',\n",
              " 'test_folder/test_images/Kuih Talam.jpg',\n",
              " 'test_folder/test_images/Kuih Ubi Kayu.jpg',\n",
              " 'test_folder/test_images/Onde-Onde.jpg',\n",
              " 'test_folder/test_labels.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "#download model\n",
        "gdown.download_folder(id='1QVWjX8Aa2VvIbXjDY4DyqcV_Uqw6myX7', output=\"model\", quiet=False, use_cookies=False)\n",
        "\n",
        "#download test ds\n",
        "gdown.download_folder(id='1LZIhiV9l82W4fNpfaBHyGvh8XBX6SoU2', output=\"test_folder\", quiet=False, use_cookies=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezrdTSBSK4tB"
      },
      "source": [
        "# Load CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9KGUYRtInXF",
        "outputId": "623351af-76b0-4f3e-a8f3-7d3a8f6613d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "cnn = YOLO(\"model/cnn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy69EVJRlijd"
      },
      "source": [
        "# Load ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uccgPddWlije",
        "outputId": "4abc1e54-dd1d-49e3-9884-929573967f1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Eva(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (rope): RotaryEmbeddingCat()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x EvaBlock(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): EvaAttention(\n",
              "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): SwiGLU(\n",
              "        (fc1_g): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (fc1_x): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (act): SiLU()\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
              "        (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): Identity()\n",
              "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import timm\n",
        "import torch\n",
        "\n",
        "vit = timm.create_model('eva02_base_patch14_224.mim_in22k', pretrained=False, num_classes=8)\n",
        "\n",
        "vit.load_state_dict(torch.load(\"model/vit.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "vit.eval().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6aed2csNlije"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "vit_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ARD7OneK7m-"
      },
      "source": [
        "# Load labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rxPynozK9bt",
        "outputId": "132c3516-970a-452a-9660-723c7563c7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Kek Lapis', 1: 'Kuih Kaswi Pandan', 2: 'Kuih Ketayap', 3: 'Kuih Lapis', 4: 'Kuih Seri Muka', 5: 'Kuih Talam', 6: 'Kuih Ubi Kayu', 7: 'Onde-Onde'}\n"
          ]
        }
      ],
      "source": [
        "with open('model/labels.txt') as f:\n",
        "    labels = {i: line.strip().split(' ', 1)[1] for i, line in enumerate(f)}\n",
        "\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCF4pb9RLYmy"
      },
      "source": [
        "# Load test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "plLuztQkLZ-C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "test_images = [os.path.join(r, f) for r, d, fs in os.walk('test_folder/test_images') for f in fs if f.lower()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af3qD8cTLoOH"
      },
      "source": [
        "# CNN predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D1cERQ3iLlMm"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "num_classes = 8\n",
        "cnn_predictions = []\n",
        "\n",
        "for path in test_images:\n",
        "    cnn_results = cnn(path, verbose=False)\n",
        "    cnn_pred_classes = cnn_results[0].boxes.cls.tolist()  # List of detected class IDs\n",
        "\n",
        "    if len(cnn_pred_classes) > 0:\n",
        "        cnn_counts = Counter(cnn_pred_classes)\n",
        "        cnn_probs = [cnn_counts.get(i, 0) for i in range(num_classes)]\n",
        "        cnn_probs = [p / sum(cnn_probs) for p in cnn_probs]  # normalize to sum to 1\n",
        "        cnn_predicted_class_idx = int(max(cnn_counts, key=cnn_counts.get))\n",
        "    else:\n",
        "        cnn_probs = [0.0] * num_classes\n",
        "        cnn_predicted_class_idx = -1\n",
        "\n",
        "    cnn_predictions.append({\n",
        "        'image': os.path.basename(path),\n",
        "        'predicted_class_index': cnn_predicted_class_idx,\n",
        "        'predicted_label': labels.get(cnn_predicted_class_idx, 'Unknown'),\n",
        "        'class_probabilities': cnn_probs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MK19SDlije"
      },
      "source": [
        "# ViT predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH4Sauvblije",
        "outputId": "48dd9102-8414-4f6e-aca2-1554208f0f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image': 'Kuih Talam.jpg', 'predicted_class_index': 5, 'predicted_label': 'Kuih Talam', 'class_probabilities': [1.3167627912480384e-05, 1.2136812074459158e-05, 1.1066323168051895e-05, 1.3946809303888585e-05, 1.3211690202297177e-05, 0.9999121427536011, 1.1822028682217933e-05, 1.2464719475246966e-05]}, {'image': 'Kuih Ubi Kayu.jpg', 'predicted_class_index': 6, 'predicted_label': 'Kuih Ubi Kayu', 'class_probabilities': [1.235513627761975e-05, 1.1472143341961782e-05, 1.0525453035370447e-05, 1.1296028787910473e-05, 1.2430575225153007e-05, 1.3341530575416982e-05, 0.9999176263809204, 1.0970372386509553e-05]}, {'image': 'Kuih Ketayap.jpg', 'predicted_class_index': 2, 'predicted_label': 'Kuih Ketayap', 'class_probabilities': [1.1390026884328108e-05, 1.3869734175386839e-05, 0.9999198913574219, 9.086344107345212e-06, 1.0420495527796447e-05, 1.1227072718611453e-05, 9.811946256377269e-06, 1.4303757779998705e-05]}, {'image': 'Kuih Lapis.jpg', 'predicted_class_index': 3, 'predicted_label': 'Kuih Lapis', 'class_probabilities': [5.841666643391363e-05, 3.0091696316958405e-05, 2.3217407942865975e-05, 0.99977046251297, 2.796222543111071e-05, 3.149258191115223e-05, 2.7370986572350375e-05, 3.096113505307585e-05]}, {'image': 'Onde-Onde.jpg', 'predicted_class_index': 7, 'predicted_label': 'Onde-Onde', 'class_probabilities': [1.3877181118004955e-05, 1.3199171917221975e-05, 1.2854003216489218e-05, 1.2150698239565827e-05, 1.2754970157402568e-05, 1.2719452570308931e-05, 1.2249536666786298e-05, 0.9999102354049683]}, {'image': 'Kuih Seri Muka.png', 'predicted_class_index': 4, 'predicted_label': 'Kuih Seri Muka', 'class_probabilities': [1.4321019079943653e-05, 1.616241570445709e-05, 1.2784389582520816e-05, 1.3969887731946073e-05, 0.9999080896377563, 1.4388646377483383e-05, 1.1212988283659797e-05, 9.139475878328085e-06]}, {'image': 'Kuih Kaswi Pandan.jpg', 'predicted_class_index': 1, 'predicted_label': 'Kuih Kaswi Pandan', 'class_probabilities': [2.2194763005245477e-05, 0.9998972415924072, 1.859329677245114e-05, 2.0087854863959365e-05, 1.404506474500522e-05, 1.133694877353264e-05, 1.0026237760030199e-05, 6.448821295634843e-06]}, {'image': 'Kek Lapis.jpg', 'predicted_class_index': 0, 'predicted_label': 'Kek Lapis', 'class_probabilities': [0.9998119473457336, 2.1981390091241337e-05, 2.3216709450935014e-05, 3.76602984033525e-05, 2.7468435291666538e-05, 2.642870822455734e-05, 2.8511378332041204e-05, 2.2864158381707966e-05]}]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "vit_predictions = []\n",
        "\n",
        "for path in test_images:\n",
        "    image = Image.open(path).convert(\"RGB\")\n",
        "    input_tensor = vit_transform(image).unsqueeze(0).cpu()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vit_logits = vit(input_tensor)\n",
        "\n",
        "    vit_probs_tensor = F.softmax(vit_logits, dim=1).squeeze(0)\n",
        "    vit_probs = vit_probs_tensor.tolist()\n",
        "\n",
        "    vit_predicted_class_idx = int(torch.argmax(vit_probs_tensor).item())\n",
        "\n",
        "    vit_predictions.append({\n",
        "        'image': os.path.basename(path),\n",
        "        'predicted_class_index': vit_predicted_class_idx,\n",
        "        'predicted_label': labels.get(vit_predicted_class_idx, 'Unknown'),\n",
        "        'class_probabilities': vit_probs\n",
        "    })\n",
        "\n",
        "print(vit_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm3Jc2y1lijf"
      },
      "source": [
        "# Combine model outputs and decide on one class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yB712MKNlijf"
      },
      "outputs": [],
      "source": [
        "final_predictions = []\n",
        "\n",
        "for cnn, vit in zip(cnn_predictions, vit_predictions):\n",
        "    assert cnn['image'] == vit['image'], \"Mismatch in image order\"\n",
        "\n",
        "    cnn_idx = cnn['predicted_class_index']\n",
        "    vit_idx = vit['predicted_class_index']\n",
        "    cnn_probs = cnn['class_probabilities']\n",
        "    vit_probs = vit['class_probabilities']\n",
        "\n",
        "    #average probabilities (soft voting)\n",
        "    final_probs = [(c + v) / 2 for c, v in zip(cnn_probs, vit_probs)]\n",
        "\n",
        "    # Decide class index from final_probs\n",
        "    if cnn_idx == vit_idx and cnn_idx != -1: #models cohere\n",
        "        final_idx = cnn_idx\n",
        "\n",
        "    elif cnn_idx == -1 and vit_idx != -1: #CNN no output, ViT has output, follow ViT\n",
        "        final_idx = vit_idx\n",
        "\n",
        "    elif vit_idx == -1 and cnn_idx != -1: #ViT no output, CNN has output, follow CNN\n",
        "        final_idx = cnn_idx\n",
        "\n",
        "    elif cnn_idx != -1 and vit_idx != -1: #models disagree, compare confidences from both models using soft voting\n",
        "        final_idx = int(torch.tensor(final_probs).argmax().item())\n",
        "    else:\n",
        "        final_idx = -1  #both models no output\n",
        "\n",
        "    final_predictions.append({\n",
        "        'image': cnn['image'],\n",
        "        'predicted_class_index': final_idx,\n",
        "        'predicted_label': labels.get(final_idx, 'Unknown'),\n",
        "        'class_probabilities': final_probs\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETnBcJfcNQOW"
      },
      "source": [
        "# Save results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpAgJ5JcNRVj",
        "outputId": "3defb103-cfc7-4875-e6aa-f2518f267b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   image  predicted_class_index    predicted_label  \\\n",
            "0         Kuih Talam.jpg                      5         Kuih Talam   \n",
            "1      Kuih Ubi Kayu.jpg                      6      Kuih Ubi Kayu   \n",
            "2       Kuih Ketayap.jpg                      2       Kuih Ketayap   \n",
            "3         Kuih Lapis.jpg                      3         Kuih Lapis   \n",
            "4          Onde-Onde.jpg                      7          Onde-Onde   \n",
            "5     Kuih Seri Muka.png                      4     Kuih Seri Muka   \n",
            "6  Kuih Kaswi Pandan.jpg                      1  Kuih Kaswi Pandan   \n",
            "7          Kek Lapis.jpg                      0          Kek Lapis   \n",
            "\n",
            "                                 class_probabilities  \n",
            "0  [6.583813956240192e-06, 6.068406037229579e-06,...  \n",
            "1  [6.177568138809875e-06, 5.736071670980891e-06,...  \n",
            "2  [5.695013442164054e-06, 6.934867087693419e-06,...  \n",
            "3  [2.9208333216956817e-05, 1.5045848158479203e-0...  \n",
            "4  [6.938590559002478e-06, 6.599585958610987e-06,...  \n",
            "5  [7.160509539971827e-06, 8.081207852228545e-06,...  \n",
            "6  [1.1097381502622738e-05, 0.9999486207962036, 9...  \n",
            "7  [0.9999059736728668, 1.0990695045620669e-05, 1...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "final_results_df = pd.DataFrame(final_predictions)\n",
        "print(final_results_df)\n",
        "final_results_df.to_csv(\"predictions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxzdFncN8hB"
      },
      "source": [
        "# Map the true labels of the images in the testing folder to model's class index (from here onwards will be the original organisers' code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tAm29rH2ODc3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('test_folder/test_labels.txt')\n",
        "\n",
        "filename_to_class = dict(zip(df_test['Filename'].str.strip(), df_test['Class'].str.strip()))\n",
        "\n",
        "label_to_class_index = {v.strip(): k for k, v in labels.items()}\n",
        "\n",
        "true_class_index = [label_to_class_index[filename_to_class[os.path.basename(path).strip()]] for path in test_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V_uh8KJROLrO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "final_results_df['true_class_index'] = true_class_index  ## changes here in v2 - refer to true_class_index\n",
        "y_true = final_results_df['true_class_index'].astype(int).values\n",
        "y_pred = final_results_df['predicted_class_index'].astype(int).values\n",
        "y_probs = np.array(final_results_df['class_probabilities'].tolist())\n",
        "\n",
        "n_classes=8\n",
        "\n",
        "# Pad probability vectors to length 8\n",
        "def pad_probs(probs, target_len=n_classes):\n",
        "    padded = np.zeros(target_len)\n",
        "    padded[:len(probs)] = probs  # assumes probs are in order (class 0, 1, 2, ...)\n",
        "    return padded\n",
        "\n",
        "# Apply padding\n",
        "y_probs_padded = np.array([pad_probs(p, n_classes) for p in final_results_df['class_probabilities']])\n",
        "\n",
        "# Update your DataFrame or use directly in metrics\n",
        "y_probs = y_probs_padded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g44fTDfKQ0QY",
        "outputId": "1032f662-dffc-43eb-b3f0-ba2f1306499a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Accuracy: 1.0000\n",
            "\n",
            "📊 Per-class metrics:\n",
            "Class 0: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 1: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 2: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 3: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 4: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 5: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 6: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "Class 7: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
            "\n",
            "📦 Macro Precision: 1.0000, Macro Recall: 1.0000, Macro F1: 1.0000\n",
            "\n",
            "🎯 ROC AUC per class:\n",
            "Class 0: AUC = 1.0000\n",
            "Class 1: AUC = 1.0000\n",
            "Class 2: AUC = 1.0000\n",
            "Class 3: AUC = 1.0000\n",
            "Class 4: AUC = 1.0000\n",
            "Class 5: AUC = 1.0000\n",
            "Class 6: AUC = 1.0000\n",
            "Class 7: AUC = 1.0000\n",
            "\n",
            "🌐 Macro ROC AUC: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Number of classes\n",
        "class_names = list(range(n_classes))\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\n✅ Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Precision, Recall, F1 per class & macro\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_names, average=None)\n",
        "macro_prec, macro_rec, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "\n",
        "print(\"\\n📊 Per-class metrics:\")\n",
        "for i, cls in enumerate(class_names):\n",
        "    print(f\"Class {cls}: Precision={prec[i]:.4f}, Recall={rec[i]:.4f}, F1={f1[i]:.4f}\")\n",
        "\n",
        "print(f\"\\n📦 Macro Precision: {macro_prec:.4f}, Macro Recall: {macro_rec:.4f}, Macro F1: {macro_f1:.4f}\")\n",
        "\n",
        "# ROC AUC (requires binarized labels)\n",
        "y_true_bin = label_binarize(y_true, classes=class_names)\n",
        "\n",
        "# ROC AUC per class and macro\n",
        "try:\n",
        "    auc_per_class = roc_auc_score(y_true_bin, y_probs, average=None, multi_class='ovr')\n",
        "    auc_macro = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n",
        "\n",
        "    print(\"\\n🎯 ROC AUC per class:\")\n",
        "    for i, cls in enumerate(class_names):\n",
        "        print(f\"Class {cls}: AUC = {auc_per_class[i]:.4f}\")\n",
        "\n",
        "    print(f\"\\n🌐 Macro ROC AUC: {auc_macro:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ ROC AUC could not be computed: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}